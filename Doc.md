# How to run the simulations 
## 1. **Build the Podman image**
Run the following command: `podman build -t <imageName>:<tag> <folder>`. 
- `imageName`:  Assigns a name and optionally a tag to the image being built
- `folder`: Specifies the directory containing the Dockerfile and all the required files for the build
This Dockerfile sets up a video quality analysis environment with Python 3.12, FFmpeg 7.0.2, and VMAF 3.0.0. It installs necessary development tools, libraries for video encoding, and Python packages for analysis. The container is configured to run video quality experiments, store results, and generate graphs using pre-defined scripts and MOS data.
## 2. **Modify the configuration file in the JSON folder** 

The configuration file contains several fields:
  - `IMAGE_NAME` : the name of the Docker image used to execute the commands.
  - `INPUT_REF_DIR`: the directory containing reference videos.
  - `INPUT_DIST_DIR`: the directory containing distorted videos, i.e., compressed or altered videos to be compared with the reference videos.
  - `OUTPUT_DIR`: directory where the analysis results, such as JSON files generated by VMAF and graphs, are saved.
  - `HASH_DIR`: Directory for saving hash or checksum files, generated using the md5sum command
  - `MOS_DIR`: Directory where the Mos description files can be found
  - `DATASET_DIR`: Directory where datasets description files can be found
  - `REFERENCE_VIDEO_LIST_DIR`: Directory where the text files listing the original video files can be found.
  - `JSON_DIR`: Directory where the JSON configuration file and the JSON schema model can be found.
  - `ORIGINAL_VIDEO`: The name of the original YUV or Y4M file to be used as the reference video in the analysis.
  - `MODEL_VERSION` :  Specifies the version or group of VMAF models to be used for the analysis.
    - Example: `VMAF_ALL` indicates that all available VMAF models will be used.
    - Example 2 : `vmaf_v0.6.1.json` indicates that the vmaf will run with that model
    - Example 3: `[vmaf_v0.6.1.json,vmaf_v0.6.1neg.json]` indicates that the vmaf will run with two models
  - `DATASET`:  The name of the dataset that will be analyzed
  - `FEATURES`: A list of metrics or features to be calculated during the vmaf analysis.
    - `cambi`: CAMBI (Contrast Aware Multiscale Banding Index) is Netflix's detector for banding (aka contouring) artifacts.
    - `float_ssim`: Structural Similarity Index Metric in floating-point precision.
    - `psnr`: A metric that measures the quality of the image by comparing the peak signal to the noise.
    - `float_ms_ssim`: Multi-Scale SSIM in floating-point precision.
    - `ciede`: CIEDE2000
    - `psnr_hvs`: PSNR optimized for the Human Visual System.
    - `USE_LIBVMAF`: This can be set to true or false. If set to true, the VMAF evaluation will be executed.
    - `USE_Essim`: This can be set to true or false. If set to true, the eSSIM evaluation will be executed.
    The `ESSIM_PARAMETERS` is a list of objects that contains the following configurable settings:
       - `Window_size`: This parameter defines the window size for the eSSIM calculation and can be either "8" or "16". The default value is "8".
       - `Window_stride`: This parameter specifies the window stride for eSSIM and can be one of "4", "8", or "16". The default value is "4".
       - `SSIM_Minkowski_pooling`: This parameter sets the SSIM Minkowski pooling value, which can be either "3" or "4". The default value is "3".
       - `Mode`: This parameter defines the mode of the SSIM calculation. It can be "0" (SSIM_MODE_REF), "1" (SSIM_MODE_INT), or "2" (SSIM_MODE_PERF), with the default set to "2".
    
    These parameters configure the ESSIM (Enhanced Structural SIMilarity) evaluation method.These parameters require `USE_ESSIM` to be set to true in order to be applied

## 3. **Generate Podman commands with the Python script `run_simulation_create_commands.py Json/config.json`:**  
The Python script `run_simulation_create_commands.py` automates the process of generating Podman commands to run VMAF on reference and distorted videos. It is based on the functionality of the `create_commands.py` script and performs several key tasks:
  - Reading a JSON configuration file and validating it against a JSON schema.The file is read to obtain the necessary information for OUTPUT_DIR, DATASET, REFERENCE_VIDEO_LIST_DIR and JSON_DIR.
  - Updating Configuration: For each original video file listed in a text file (e.g., DATASETNAME_reference_video_list.txt), it updates the JSON configuration file (config.json) by setting the ORIGINAL_VIDEO field to the current YUV file.
  - Executing Command Generation: It calls create_commands.py with the updated JSON configuration, generating Podman commands to process the videos.
  - Cleaning Up: Before generating new commands, it deletes any previous commands_{DATASETNAME} file from earlier runs to ensure
    that the output is up-to-date.
The Podman commands are generated for each original video and saved in `OUTPUT_DIR/{DATASETNAME}/commands_{DATASETNAME}`.
### The python script `create_commands.py`
 The python script `create_commands.py`  generates podman commands to run VMAF on reference and distorted videos. 
 The main functionalities include:
   - Reading a JSON configuration file and validating it against a JSON schema.
   - Comparing the names of distorted videos with the original video's name using regex.
   - Retrieving information (resolution, bitrate, codec, etc.) from a metadata JSON dataset file.
   - Creating commands to run the VMAF script with Podman and saving them to a commands.txt file.
   - Supporting multiple models: Allows the use of one or more VMAF models specified in the configuration.              
   -Passing the USE_LIBVMAF parameter as either true or false in the command for the VMAF evaluation
  - Passing the USE_ESSIM parameter as either true or false in the command, along with the ESSIM_PARAMS_STRING_LIST for the eSSIM evaluation     

  To run the script : `python3 create_commands.py Json/config.json`.
  The output is saved in `OUTPUT_DIR/{DATASETNAME}/commands_{DATASETNAME}`
## 4. **Run the  run_vmaf_simulation.py script to ecxecute the simulation**
  
Every command is a shell command that runs a shell file `run_experiments.sh`.
This script is designed to process video files for quality assessment using a variety of parameters. 
- The script expects 24 arguments, such as directories for reference and distorted videos, output paths, model version, dataset details, hash_dir_server,mos_dir_server and output_dir_server , video properties (e.g., resolution, codec, bitrate) , use_libmaf and use_essim flag and the essim_params_string.
- It checks that the necessary directories for input, output, mos and hashes exist, exiting with an error if any are missing.It defines file paths for the original and distorted videos, as well as output paths for decoded and resized versions.
- The script decodes the distorted video using ffmpeg,if the decoded file does not already exist, with different options based on the dataset. It may convert the video to a specific format (e.g., .y4m or .yuv).
    - For ITS4S, decode to YUV420p in a .y4m file.
    - For AGH_NTIA_Dolby, the distorted video is already in .y4m format, so simply copy the file.
    - For AVT-VQDB-UHD-1_1, decode to YUV422p in a .yuv file.
    - For AVT-VQDB-UHD-1_2, AVT-VQDB-UHD-1_3, and AVT-VQDB-UHD-1_4, decode to YUV422p with 10-bit depth in a .yuv file.
    - For KUGVD, GamingVideoSet1, and VideoGamingSet2, decode to YUV420p in a .yuv file.
- Depending on the dataset, it may resize the video to specific dimensions (e.g., 1280x720 or 1920x1080),if the decodedand resized  file does not already exist, using ffmpeg if the current resolution doesn't match the target.
    - For ITS4S and AGH_NTIA_Dolby, resize to 1280x720.
    - For KUGVD, GamingVideoSet1, and GamingVideoSet2, resize to 1920x1080.
    - For AVT-VQDB-UHD-1_1, resize to 4000x2250 for bigbuck_bunny_8bit.yuv related files, and 3840x2160 for others.
    - For AVT-VQDB-UHD-1_2, AVT-VQDB-UHD-1_3, and AVT-VQDB-UHD-1_4, resize to 3840x2160.
- It generates a hash of the decoded video file. 
- The script runs the vmaf simulation. If the model is vmaf_v0.6.1.json, it also runs the feature extraction. The vmaf simulation generates a JSON file as output.
  - VMAF parameters setup:
    - referencevideo: Path to the reference .y4m or .yuv video.
        - For ITS4S, convert the original video to YUV420p.
        - For AVT-VQDB-UHD-1_1, convert the reference video to YUV422 with 8-bit depth if the original video is different from bigbuck_bunny_8bit.yuv.
        - For AVT-VQDB-UHD-1_4, some videos have a different frame rate than the reference; convert the reference video to 30fps or 15fps.
    - distortedvideo: Decoded or decoded and resized distorted video.
    - model: Path to the VMAF model.
    - $feature_args: Used only when the model is vmaf_v0.6.1.json.
    - output: Write output as a JSON file.
    - threads: Specify the number of threads to use for processing.
- The script runs also the eSSIM simulation. 
  -  The script first checks if the USE_ESSIM variable is set to "True".  If it is, the eSSIM evaluation will be executed.
  - The script reads ESSIM_PARAMS_STRING, which is a comma-separated string, and splits it into an array called essim_params_strings_array.
  - A function parse_model is defined to extract four parameters from each entry in ESSIM_PARAMS_STRING using sed:

    - wsize: Extracted by searching for "ws" followed by a number.

    - wstride: Extracted by searching for "wt" followed by a number.

    - mink: Extracted by searching for "mk" followed by a number.

    - mode: Extracted by searching for "md" followed by a number.


  - The script set file paths:

    - final_original_file_essim and final_decoded_file_essim are initialized with values based on the original video file and the decoded video file.
    - If the DATASET is "AVT-VQDB-UHD-1_1", a check is made to see if the original video is bigbuck_bunny_8bit.yuv. If it is not, it uses a converted 8-bit reference file; otherwise, it uses the original reference file.
    - If the DATASET is "AVT-VQDB-UHD-1_4", final_original_file_essim is set to final_original_file_avt_1_4.
  
  - The script does Dataset-specific video file conversion:

    - For the dataset "ITS4S", if the video file has not been converted yet, it uses ffmpeg to convert the original video to raw YUV420p format and saves it as final_original_file_essim. The same is done for the decoded video.
    - For the dataset "AGH_NTIA_Dolby", the script converts the original video to YUV422p format and also converts the decoded video if necessary.
  - The script runs eSSIM evaluation:

    - Once the appropriate video files are prepared (either converted or original), the script runs the eSSIM evaluation by executing the essim command. It passes several parameters to the command:
        - r specifies the reference video (final_original_file_essim).
        - d specifies the distorted (decoded) video (final_decoded_file_essim).
        - w and -h specify the width and height of the video (width_new and height_new).
        - bd specifies the bit depth (BIT_DEPTH).
        - wsize, -wstride, -mink, and -mode are set to the values extracted earlier from ESSIM_PARAMS_STRING.
        - o specifies the output file for the eSSIM result (output_essim). The essim results are saved in `OUTPUT_DIR/{DATASETNAME}/essim_results`

  - Exit if USE_ESSIM is not set to "True": If `USE_ESSIM` is not set to "True", the script does nothing and the block of code is skipped.
  
## 5. **Generate  the final CSV with the script run_create_csv.sh** 
This script checks if a virtual environment named csv_virtual_env exists. If it does not, the script performs the following steps:
  - It creates the virtual environment using python3 -m venv csv_virtual_env.
  - It activates the environment by sourcing its activation script.
  - It installs the required packages listed in the requirements.txt file. (pandas,numpy,scipy and matplotlib)
  - It runs the `analyze_results_script.py` script with these arguments :   `$result_dir`, `$mos_dir`, `$dataset`, `$use_libvmaf`,`$use_essim`
  - After the script finishes running, it deactivates the virtual environment. 
  
If the virtual environment already exists, the script skips the creation and installation steps, directly activates the environment and runs the `analyze_results_script.py` with the same parameters described before then deactivates the environment afterward.
The script installs the required packages listed in the requirements.txt file, which includes specific versions of libraries such as pandas, numpy, scipy, and matplotlib. By specifying these versions in the requirements.txt, it ensures that the correct dependencies are installed, providing a consistent environment for the script to run. This helps to avoid compatibility issues and ensures reproducibility across different systems or environments.

The following feature values are calculated only for the `vmaf_v0.6.1 model`, : `cambi, float_ssim, psnr_y, psnr_cb, psnr_cr, float_ms_ssim, ciede2000, psnr_hvs_y, psnr_hvs_cb, psnr_hvs_cr, psnr_hvs, integer_vif_scale3, eSSIM, and SSIM`


### The analyze_results_script.py

This script performs the following steps:

   - Argument validation: Checks if the correct number of arguments are provided when running the script. If not, it prints a usage message and exits.
   - Input Variables:

    - result_dir: Directory that contains the JSON result files from libvmaf and the CSV result files from eSSIM.
    - mos_dir: Directory containing the JSON MOS description files
    - Dataset: The name of the dataset.
    - use_libvmaf: A boolean flag indicating whether libvmaf should be use 
    - use_essim: A boolean flag indicating whether eSSIM should be used
   - Prints Input Parameters: Prints the values of result_dir, mos_dir, dataset, use_libvmaf, and use_essim.
   - Directory Setup: Sets up the paths for vmaf_results and essim_results within the result_dir.

   - Processing VMAF Results:

    Loops through the files in the vmaf_results directory.

    - For each file, extracts information from the filename (such as dataset, original video, distorted video, dimensions, bitrate, codec, fps, and model version).
    - Constructs a command to analyze the VMAF results using analyze.py and executes it.

   - Processing eSSIM Results:

    Loops through the files in the essim_results directory.

    - Extracts information from the filename similar to how it’s done for VMAF
    - Constructs a command to analyze the eSSIM results using analyze.py and executes it.

  - Command Execution: For both VMAF and eSSIM files, the script builds and executes a subprocess command to run the analysis.

The final csv contains:
  - for every distorted file :
    - for each temporal pooling :
      - the vmaf scores for the 9 vmaf models 
      - the different features values
      - It also has columns vmaf_{model}_bagging,vmaf_{model}_stddev,vmaf_{model}_ci_p95_lo and vmaf_{model}_ci_p95_hi. These columns represent advanced VMAF metrics for the v0.6.3 model, both in floating-point (float) and integer versions:
      - Bagging: Average of the predictions from a lot of  models.
      - Stddev: Standard deviation of predictions
      - CI p95 lo/hi: Lower (lo) and upper (hi) bounds of the 95% confidence interval for the estimated score.
      - integer_vif_scale3
      - N additional columns: eSSIM and SSIM. These represent the results of the eSSIM evaluation and the SSIM derived from the previous eSSIM evaluation. They are paired together, with each pair corresponding to the essim_param_string extracted from the JSON configuration file.

### The python script `analyze.py`

The script 
-  checks if the correct number of arguments are passed (17 or 18) These arguments include details about the dataset, video characteristics, and output directory.
- loads a JSON file containing MOS scores for different videos and extracts the MOS, confidence interval (CI), and computed MOS for the distorted video. (Not every dataset has CI)
- It checks if a CSV file with combined results for the dataset exists. If not, it creates the CSV file and adds rows for temporal pooling values (mean, harmonic mean, etc.). If the file exists, it checks if the distorted video is already included; if not, it adds new rows.

- The script constructs a JSON file path based on various parameters (like dataset, video resolution, codec) and loads the results from this file. If eSSIM parameters are provided, the script constructs filenames for eSSIM result files in a similar way.
- The script loads and processes VMAF data. If the flag use_libvmaf is set to "True", the code extracts data from the frames of a video. The variable frames_list contains a list of frames, each having a frame number and associated metrics.  These data are transformed into a row-by-row format (frames_rows), where each row is a combination of the frame number and its metrics. A pandas DataFrame (dframes) is then created to collect all the rows of data.
- The script processes eSSIM data. If both use_essim and use_libvmaf are set to "True", the code loads CSV files containing eSSIM results. It then merges the VMAF data (dframes) with the eSSIM data (essim_dframes) by joining them on the frame number. The result is a unified DataFrame (merged_df) containing both VMAF and eSSIM metrics for each frame. If use_essim is "True" and use_libvmaf is "False", only the eSSIM data is loaded, and the VMAF data is ignored.


- The script calculates and stores metrics results. It initializes an empty dictionary metrics_results to store the computed results for each metric. It then iterates over the list of metrics to evaluate (metrics_to_evaluate). For each metric, the script checks if both use_essim and use_libvmaf are set to "True". If so, it calculates the metric using the merged VMAF and eSSIM data. If only use_essim is "True", it calculates the metric using only the eSSIM data. If neither condition is met, the metric is calculated using just the VMAF data.
After the metric is calculated, the results (such as mean, harmonic mean, geometric mean, etc.) are stored in the metrics_results dictionary.
Example of metrics_results:
   For each metric, the results are stored as a dictionary with values such as mean, harmonic mean, geometric mean, etc.
        For example, metrics_results["ciede2000"] could look like {mean, harmonic_mean, geometric_mean, percentile_50, percentile_5, percentile_95, norm_lp_1, norm_lp_2, norm_lp_3}.
  The function `calculate_metrics` handles cases where columns contain missing or NaN values, in which case it returns a default value of -1.
- The script fills the dataframe with the calculated metrics:
    The script then loads an existing CSV file (df_existing) into a DataFrame.
    A function fill_dataframe is defined to fill the dataframe with calculated metric values for a given column. It updates the specified rows (starting from start_row and spanning temporal_pooling_count rows) with values for the metric (mean, harmonic mean, geometric mean, etc.).
- The script process the metrics and updates the dataframe:
  The script checks the model_version to determine which metrics to process.
    - If the model version is among the specified ones (vmaf_v0.6.1.json, vmaf_b_v0.6.3.json, vmaf_float_b_v0.6.3.json), it calls the process_metrics function to process and fill in the calculated metrics into the DataFrame.
      - In the process_metrics function:
        The model_base is derived from the model version (by removing .json).
        The script searches for the first occurrence of distorted_video in the Distorted_file_name column of the DataFrame.
        For each metric in metrics_results, it determines the appropriate column name and calls fill_dataframe to update the DataFrame with the metric values.
   -  If the model version is not among the specified ones but "vmaf" is present in metrics_results, the script directly fills the dataframe with the values of the vmaf metric, following similar steps as described above.

- After processing all metrics and filling the DataFrame, the script writes the updated DataFrame to the CSV file, overwriting the existing content (mode='w'). The script then prints a message confirming that the column for the specified model_version has been added to the CSV file.




## 6. **Run the run_create_graphs.sh script to generate the graphs**
This script checks if a virtual environment named `csv_virtual_env` exists. If it doesn't, it creates the environment, activates it, installs the required packages from `requirements.txt`, and then runs the `graph_script.py` script  with `$output_dir"` and `"$dataset"`  arguments.
The script installs the required packages listed in the requirements.txt file, which includes specific versions of libraries such as pandas, numpy, scipy, and matplotlib. By specifying these versions in the requirements.txt, it ensures that the correct dependencies are installed, providing a consistent environment for the script to run. This helps to avoid compatibility issues and ensures reproducibility across different systems or environments.
After the script execution, it deactivates the virtual environment. If the virtual environment already exists, the script simply activates it and runs the `graph_script.py`  script with `$output_dir"` and `"$dataset"`  arguments.

### The python script `graph_script`

The script : 
- The code checks if there are fewer than 3 command-line arguments, and if so, prints an error message and exits the script with a status code of 1.

- Axis limits are set by a dictionary. The code defines the range (min, max) for various metrics (e.g., VMAF, PSNR , eSSIM,etc.).

- temporal_pooling_marker_map:  Maps different temporal pooling methods (e.g., mean, harmonic mean, geometric mean) to specific markers for plotting (e.g., 'o', 'x', 'h')

- File and Dataset Setup:

    - The script takes two command-line arguments: output directory (output_dir) and dataset name (dataset).

   -  Constructs the file path for a CSV file containing the dataset's combined results (combined_results_dataset.csv). The script checks if the specified CSV file exists. If not, it prints an error message and exits.

- Defines columns (x_column) and models/features to be used for plotting. For eSSIM and SSIM features, their axis limits are adjusted dynamically if they are found in the dataset.Specifies also which temporal pooling methods will be used for plotting, such as mean, harmonic_mean, geometric_mean, percentile_50, etc. 

- The script sets up paths for saving various plots:
- Extract all the different pvs
- Defines color palettes for different temporal pooling methods and VMAF models, ensuring that each method/model has a unique color for plotting

- The script generates the following graphs :

  - A graph for each feature present in features (list of video quality metrics considered):

    For each pvs value, it extracts the mean value of the feature, the corresponding MOS value, and generates a scatter plot between MOS and the selected feature.

    Another graph is produced that plots all the pooling values, not just the mean.

  -  A graph for each VMAF model in vmaf_models (list of VMAF models), repeating the previous process but in this case, visualizing the values from the VMAF models vs MOS for each pvs.
 
 - A graph that plots the values of the various VMAF models against MOS for different pooling methods (mean, harmonic mean, and geometric mean).

- A graph that plots the values of the various VMAF models against MOS for different pooling methods (mean, median, L1 norm, L2 norm, L3 norm)

- An error plot graph with corresponding confidence limits (lo/hi) for the "float b" VMAF model (vmaf_float_b_v0.6.3), plotting the mean value.

- An error plot graph with corresponding confidence limits (lo/hi) for the "float b" VMAF model (vmaf_float_b_v0.6.3), but with the mean value centered relative to the standard deviation (information is taken from vmaf_float_b_v0.6.3_stddev). The mean value is plotted.

- Two additional graphs similar to the previous two, but this time for the "b" VMAF model (vmaf_b_v0.6.3).

- A graph that uses error bars for various VMAF models, with extreme values being the 5th and 95th percentiles, and the central value being the mean or median (95th percentile) (on the same graph).

- A graph comparing the mean value of two models with respect to MOS.


# Requirements
- A JSON dataset file with the following structure:
```json
{
  "database": "DatasetName",
  "reference_videos": [ {
      "id": 1,
      "file_name": "CSGO_30fps_30sec_Part1.yuv"
    },
    ...
  ],
  "distorted_videos": [
    {
      "id": 1,
      "file_name": "CSGO_30fps_30sec_Part2_1280x720_1200_x264.mp4",
      "width": 1280,
      "height": 720,
      "bitrate": 1200,
      "video_codec": "x264",
      "bitdepth": 8,
      "pixel_format": "420",
      "fps": 30,
      "duration": 30
    },
  ]
}
```
- A JSON file with the Mean Opinion Score (MOS). It is essential that the PVS_ID matches the file_name field of the distorted video in the distorted_videos JSON structure. The MOS file can also include additional fields such as Confidence Intervals (CI).
````json
"scores": [
        {
            "PVS": {
                "PVS_ID": "CSGO_30fps_30sec_Part2_1280x720_1200_x264",
                "SRC": "CSGO",
                "fps": 30,
                "duration": 30,
                "parts": "Part2",
                "width": 1280,
                "height": 720,
                "bitrate": 1200.0,
                "encoder": "x264",
                "yuv_fmt": "yuv420p"
            },
            "MOS": 2.88
        },
]
```