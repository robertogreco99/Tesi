# How to run the simulations 
## 1. **Build the Podman image**
Run the following command: `podman build -t <imageName> <folder>`. 

This Dockerfile sets up a video quality analysis environment with Python 3.12, FFmpeg 7.0.2, and VMAF 3.0.0. It installs necessary development tools, libraries for video encoding, and Python packages for analysis. The container is configured to run video quality experiments, store results, and generate graphs using pre-defined scripts and MOS data.
## 2. **Modify the configuration file in the JSON folder** 

The configuration file contains several fields:
  - `IMAGE_NAME` : the name of the Docker image used to execute the commands.
  - `INPUT_REF_DIR`: the directory containing reference videos.
  - `INPUT_DIST_DIR`: the directory containing distorted videos, i.e., compressed or altered videos to be compared with the reference videos.
  - `OUTPUT_DIR`: directory where the analysis results, such as JSON files generated by VMAF and graphs, are saved.
  - `HASH_DIR`: Directory for saving hash or checksum files, generated using the md5sum command
  - `ORIGINAL_VIDEO`: The name of the original YUV or Y4M file to be used as the reference video in the analysis.
  - `MODEL_VERSION` :  Specifies the version or group of VMAF models to be used for the analysis.
    - Example: `VMAF_ALL` indicates that all available VMAF models will be used.
    - Example 2 : `vmaf_v0.6.1.json` indicates that the vmaf will run with that model
  - `DATASET`:  The name of the dataset that will be analyzed
  - `FEATURES`: A list of metrics or features to be calculated during the vmaf analysis.
    - `cambi`: CAMBI (Contrast Aware Multiscale Banding Index) is Netflix's detector for banding (aka contouring) artifacts.
    - `float_ssim`: Structural Similarity Index Metric in floating-point precision.
    - `psnr`: A metric that measures the quality of the image by comparing the peak signal to the noise.
    - `float_ms_ssim`: Multi-Scale SSIM in floating-point precision.
    - `ciede`: CIEDE2000
    - `psnr_hvs`: PSNR optimized for the Human Visual System.
## 3. **Generate Podman commands with the Python script `run_simulation_create_commands.py`:**  
The Python script `run_simulation_create_commands.py` automates the process of generating Podman commands to run VMAF on reference and distorted videos. It is based on the functionality of the `create_commands.py` script and performs several key tasks:
  - Updating Configuration: For each original video file listed in a text file (e.g., DATASETNAME_reference_video_list.txt), it updates the JSON configuration file (config.json) by setting the ORIGINAL_VIDEO field to the current YUV file.
  - Executing Command Generation: It calls create_commands.py with the updated JSON configuration, generating Podman commands to process the videos.
  - Cleaning Up: Before generating new commands, it deletes any previous commands_{DATASETNAME} file from earlier runs to ensure
    that the output is up-to-date.
  - Instructions to set parameters in the script:
      - dataset: The name of the dataset.
      - originalvideo_list_file: Path to the text file that lists the original videos.
      - json_config_path: Path to the JSON configuration file that is updated for each YUV video.
The Podman commands are generated for each original video and saved in `OUTPUT_DIR/{DATASETNAME}/commands_{DATASETNAME}`.
### The python script `create_commands.py`
 The python script `create_commands.py`  generates podman commands to run VMAF on reference and distorted videos. 
 The main functionalities include:
   - Reading a JSON configuration file and validating it against a JSON schema.
   - Comparing the names of distorted videos with the original video's name using regex.
   - Retrieving information (resolution, bitrate, codec, etc.) from a metadata JSON dataset file.
   - Creating commands to run the VMAF script with Podman and saving them to a commands.txt file.
   - Supporting multiple models: Allows the use of one or more VMAF models specified in the configuration.                                                                                                                
   
  To run the script : `python3 create_commands.py Json/config.json`.
  The output is saved in `OUTPUT_DIR/{DATASETNAME}/commands_{DATASETNAME}`
## 4. **Run the run_vmaf_simulation.py script to execute the simulation**
Instructions to set parameters:
   - dataset = Specifies the dataset name.
   - file_path: Specifies the location of the file containing the Podman commands, e.g., f"OUTPUT_DIR/{DATASETNAME}/commands_{DATASETNAME}.txt".
   
Every command is a shell command that runs a shell file `run_experiments.sh`.
This script is designed to process video files for quality assessment using a variety of parameters. 
- The script expects 18 arguments, such as directories for reference and distorted videos, output paths, model version, dataset details, and video properties (e.g., resolution, codec, bitrate). 
- It checks that the necessary directories for input, output, mos and hashes exist, exiting with an error if any are missing.It defines file paths for the original and distorted videos, as well as output paths for decoded and resized versions.
- The script decodes the distorted video using ffmpeg,if the decoded file does not already exist, with different options based on the dataset. It may convert the video to a specific format (e.g., .y4m or .yuv).
    - For ITS4S, decode to YUV420p in a .y4m file.
    - For AGH_NTIA_Dolby, the distorted video is already in .y4m format, so simply copy the file.
    - For AVT-VQDB-UHD-1_1, decode to YUV422p in a .yuv file.
    - For AVT-VQDB-UHD-1_2, AVT-VQDB-UHD-1_3, and AVT-VQDB-UHD-1_4, decode to YUV422p with 10-bit depth in a .yuv file.
    - For KUGVD, GamingVideoSet1, and VideoGamingSet2, decode to YUV420p in a .yuv file.
- Depending on the dataset, it may resize the video to specific dimensions (e.g., 1280x720 or 1920x1080),if the decodedand resized  file does not already exist, using ffmpeg if the current resolution doesn't match the target.
    - For ITS4S and AGH_NTIA_Dolby, resize to 1280x720.
    - For KUGVD, GamingVideoSet1, and GamingVideoSet2, resize to 1920x1080.
    - For AVT-VQDB-UHD-1_1, resize to 4000x2250 for bigbuck_bunny_8bit.yuv related files, and 3840x2160 for others.
    - For AVT-VQDB-UHD-1_2, AVT-VQDB-UHD-1_3, and AVT-VQDB-UHD-1_4, resize to 3840x2160.
- It generates a hash of the decoded video file. 
- The script runs the vmaf simulation. If the model is vmaf_v0.6.1.json, it also runs the feature extraction. The vmaf simulation generates a JSON file as output.
  - VMAF parameters setup:
    - referencevideo: Path to the reference .y4m or .yuv video.
        - For ITS4S, convert the original video to YUV420p.
        - For AVT-VQDB-UHD-1_1, convert the reference video to YUV422 with 8-bit depth if the original video is different from bigbuck_bunny_8bit.yuv.
        - For AVT-VQDB-UHD-1_4, some videos have a different frame rate than the reference; convert the reference video to 30fps or 15fps.
    - distortedvideo: Decoded or decoded and resized distorted video.
    - model: Path to the VMAF model.
    - $feature_args: Used only when the model is vmaf_v0.6.1.json.
    - output: Write output as a JSON file.
    - threads: Specify the number of threads to use for processing.

The simulations generate a `analyzescriptcommands_{DATASETNAME}.txt` file in the `OUTPUT_DIR/{DATASETNAME}` folder. 
The file contains the podman commands to launch in order to create the final csv.
If you want to run simulations on additional datasets, use the Python script `run_more_vmaf_simulation.py`. In this case, you need to set multiple dataset fields and corresponding file_path fields.
  
## 5. **Run the run_analyze_script_simulation.py script to generate the final csv** 
You need to set the dataset fields to specifies where to found the file with the podman commands.
The final csv contains:
  - for every distorted file :
    - for each temporal pooling :
      - the vmaf scores for the 9 vmaf models 
      - the different features values
      - It also has columns vmaf_{model}_bagging,vmaf_{model}_stddev,vmaf_{model}_ci_p95_lo and vmaf_{model}_ci_p95_hi. These columns represent advanced VMAF metrics for the v0.6.3 model, both in floating-point (float) and integer versions:
      - Bagging: Average of the predictions from a lot of  models.
      - Stddev: Standard deviation of predictions
      - CI p95 lo/hi: Lower (lo) and upper (hi) bounds of the 95% confidence interval for the estimated score.
      - integer_vif_scale3
## 6. **Run the graph_simulations_run.py script to generate the graphs**
To create the graphs, execute the `graph_simulations_run.py` script. You will need to set the dataset field. 
This script runs `graph_script.py` and generates:
    - For each feature:
      A graph displaying all the PVS values, where each point represents the value of the PVS for that feature, calculated for a specific temporal pooling.
    - For each model:
      A graph displaying all the PVS values, where each point represents the value of the PVS for that model, calculated for a specific temporal pooling.
# Requirements
- A JSON dataset file with the following structure:
```json
{
  "database": "DatasetName",
  "reference_videos": [ {
      "id": 1,
      "file_name": "CSGO_30fps_30sec_Part1.yuv"
    },
    ...
  ],
  "distorted_videos": [
    {
      "id": 1,
      "file_name": "CSGO_30fps_30sec_Part2_1280x720_1200_x264.mp4",
      "width": 1280,
      "height": 720,
      "bitrate": 1200,
      "video_codec": "x264",
      "bitdepth": 8,
      "pixel_format": "420",
      "fps": 30,
      "duration": 30
    },
  ]
}
```
- A JSON file with the Mean Opinion Score (MOS). It is essential that the PVS_ID matches the file_name field of the distorted video in the distorted_videos JSON structure. The MOS file can also include additional fields such as Confidence Intervals (CI).
````json
"scores": [
        {
            "PVS": {
                "PVS_ID": "CSGO_30fps_30sec_Part2_1280x720_1200_x264",
                "SRC": "CSGO",
                "fps": 30,
                "duration": 30,
                "parts": "Part2",
                "width": 1280,
                "height": 720,
                "bitrate": 1200.0,
                "encoder": "x264",
                "yuv_fmt": "yuv420p"
            },
            "MOS": 2.88
        },
]
```